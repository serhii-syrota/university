Самостійна робота 1 з дисципліни **Data mining**

Студент - Сирота Сергій ТТП-42 (Serhii Syrota TTP-42)

Викладач - Криволап Андрій (PhD) (Kryvolap Andriy)

Task description:

```
Для одного з варіантів побудувати класифікатор використовуючи методи 1-Rule, Naive-Bayes, Decission Tree, kNN. Можливий варіант програмної реалізації з докладними поясненнями.
```

**Task A**

Q1 | Q2 | Q3 | Q4 | S
-- | -- | -- | -- | -
0  | 0  | 0  | 0  | 1 |
0  | 0  | 0  | 1  | 0 |
0  | 0  | 1  | 0  | 1 |
0  | 0  | 1  | 1  | 1 |
0  | 1  | 0  | 0  | 0 |
0  | 1  | 0  | 1  | 0 |
0  | 1  | 1  | 0  | 1 |
0  | 1  | 1  | 1  | 1 |
1  | 0  | 0  | 0  | 0 |
1  | 0  | 1  | 0  | 0 |
1  | 1  | 1  | 1  | ? |

# Rule 1

True/all - table:

Q1   | Q2   | Q3   | Q4
---- | ---- | ---- | ----
3/10 | 3/10 | 8/10 | 5/10

**Q3 - winner, S(10) = 1**

# Naive-Bayes

P(S=1) = 0.5; P(S=0) = 0.5; Вважаємо, що усі атрибути(Q(1-5) features) незалежні один від одного та рівні між собою за вагою(значимістю).

Множина класів: {S1, S0}

```
P(f) = P(f(d1),f(d2),f(d3),f(d4),f(d5))

P(c|f) = ( P(f | c) * P(c) )/P(f)

f = (Q1,Q2,Q3,Q4)
c = 0 | 1

Independency between features => P(Q1, Q2) = P(Q1) * P(Q2)

P(c|f) = ( P(c) * P(Q1 | c) * P(Q2 | c) * P(Q3 | c) * P(Q4 | c)) / (P(Q1) * P(Q2) * P(Q3) * P(Q4))

As the denominator remains the constant - we can remove that term
P(c|f) ~=  P(c) * P(Q1 | c) * P(Q2 | c) * P(Q3 | c) * P(Q4 | c)
```

Q1 | S(0) | S(1) | P(S(0)) | P(S(1))
-- | ---- | ---- | ------- | -------
0  | 3    | 5    | 3/8     | 5/8
1  | 0    | 2    | 0       | 1

Q2 | S(0) | S(1) | P(S(0)) | P(S(1))
-- | ---- | ---- | ------- | -------
0  | 3    | 3    | 3/6     | 3/6
1  | 2    | 2    | 2/4     | 2/4

Q3 | S(0) | S(1) | P(S(0)) | P(S(1))
-- | ---- | ---- | ------- | -------
0  | 4    | 1    | 4/5     | 1/5
1  | 1    | 4    | 1/5     | 4/5

Q4 | S(0) | S(1) | P(S(0)) | P(S(1))
-- | ---- | ---- | ------- | -------
0  | 3    | 3    | 3/6     | 3/6
1  | 2    | 2    | 2/4     | 2/4

**Finally**

Q1 | Q2 | Q3 | Q4 | S
-- | -- | -- | -- | -
1  | 1  | 1  | 1  | ?

```
P(S0 | (1,1,1,1)) = 0 * 0.5 * 0.2 * 0.5 = 0.05*0

P(S1 | (1,1,1,1)) = 1 * 0.5 * 0.8 * 0.5 = 0.2
```

Even without k-additive smoothing S1 probability is obviously higher

**S(10) = 1**
