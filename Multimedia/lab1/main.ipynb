{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb75b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from os import mkdir, path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Sound:\n",
    "    def __init__(self, path):\n",
    "        self.sound_path = path\n",
    "\n",
    "    def export_melgram(self, export_path):\n",
    "        MELS = 128\n",
    "        samples, sample_rate = librosa.load(self.sound_path, sr=None)\n",
    "        sgram = librosa.stft(samples)\n",
    "        sgram_mag, _ = librosa.magphase(sgram)\n",
    "        mel_scale_sgram = librosa.feature.melspectrogram(\n",
    "            S=sgram_mag, sr=sample_rate, n_mels=MELS)\n",
    "        mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "\n",
    "        # hack to make each mel have one pixel of height\n",
    "        fig, ax = plt.subplots(figsize=(256 / 100, 2*MELS / 100))\n",
    "        librosa.display.specshow(mel_sgram, ax=ax)\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.savefig(export_path, format='jpg',\n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "        # memory leak fix\n",
    "        plt.close(fig)\n",
    "        fig.clf()\n",
    "        del fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649973ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/Desktop/University/Multimedia/lab1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/Desktop/University/Multimedia/lab1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sound\n\u001b[1;32m      5\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/Desktop/University/Multimedia/lab1'"
     ]
    }
   ],
   "source": [
    "class UrbanSound8K:\n",
    "    def __init__(self, dataset_path: str, meta_path: str, audio_path: str):\n",
    "        self.audio_path = audio_path\n",
    "        self.images_path = path.join(dataset_path, \"images\")\n",
    "        self.data = pd.read_csv(meta_path)\n",
    "\n",
    "    def folds(self):\n",
    "        folds = []\n",
    "        for i in range(1, 11):\n",
    "            fold = path.join(self.images_path, \"fold\"+str(i))\n",
    "            folds.append(fold)\n",
    "        return folds\n",
    "\n",
    "    def generate_images(self):\n",
    "        self._ensure_image_folders()\n",
    "        for i in range(len(self.data)):\n",
    "            row = self.data.iloc[i]\n",
    "            sound_file_path = path.join(\n",
    "                self.audio_path, \"fold\"+str(row['fold']), row['slice_file_name'])\n",
    "            jpeg_folder = path.join(\n",
    "                self.images_path, \"fold\"+str(row['fold']), row['class'])\n",
    "            self._ensure_folder(jpeg_folder)\n",
    "            jpeg_path = path.join(jpeg_folder, row['slice_file_name'])+'.jpg'\n",
    "            Sound(sound_file_path).export_melgram(jpeg_path)\n",
    "\n",
    "    def _ensure_image_folders(self):\n",
    "        print(\"Creating image folders\")\n",
    "        self._ensure_folder(self.images_path)\n",
    "        for i in range(1, 11):\n",
    "            self._ensure_folder(path.join(self.images_path, \"fold\"+str(i)))\n",
    "\n",
    "    def _ensure_folder(self, folder):\n",
    "        try:\n",
    "            mkdir(folder)\n",
    "        except FileExistsError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad817bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.utils\n",
    "import keras.preprocessing\n",
    "import keras.layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import keras\n",
    "import functools\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "\n",
    "class UrbanSoundClassifier:\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self._dataset = dataset\n",
    "        self.EPOCHS = 20\n",
    "\n",
    "    def evaluate(self):\n",
    "\n",
    "        print(keras.__version__)\n",
    "        fold_img_folders = self._dataset.folds()\n",
    "\n",
    "        validate_folds = [1, 2, 3]\n",
    "        train = [x for j, x in enumerate(\n",
    "            fold_img_folders) if j in validate_folds]\n",
    "        train_datasets = [self._dataset_from_folder(\n",
    "            fold_img_folders[j]) for j in range(len(train))]\n",
    "        train_ds = functools.reduce(\n",
    "            lambda x, y: x.concatenate(y), train_datasets)\n",
    "\n",
    "        self.class_names = self._dataset_from_folder(\n",
    "            fold_img_folders[0]).class_names\n",
    "\n",
    "        validation = [x for j, x in enumerate(\n",
    "            fold_img_folders) if j not in validate_folds]\n",
    "        validation_datasets = [self._dataset_from_folder(\n",
    "            fold_img_folders[j]) for j in range(len(validation))]\n",
    "        validation_ds = functools.reduce(\n",
    "            lambda x, y: x.concatenate(y), validation_datasets)\n",
    "        model = self._create_model()\n",
    "        model.fit(train_ds, epochs=self.EPOCHS)\n",
    "        model.evaluate(validation_ds)\n",
    "\n",
    "        self._display_confusion_matrix(\n",
    "            self._calculate_confusion_matrix(model, validation_ds))\n",
    "\n",
    "    def _display_confusion_matrix(self, matrix):\n",
    "        df_cm = pd.DataFrame(matrix, index=self.class_names,\n",
    "                             columns=self.class_names)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sn.heatmap(df_cm, annot=True, fmt=\".2f\", cmap='Blues')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "\n",
    "    def _calculate_confusion_matrix(self, model: keras.Sequential, ds):\n",
    "        predicted_classes_y = np.argmax(model.predict(ds), axis=1)\n",
    "        true_labels = np.concatenate([np.argmax(y, axis=1) for x, y in ds])\n",
    "        print(true_labels)\n",
    "        print(predicted_classes_y)\n",
    "        return confusion_matrix(true_labels, predicted_classes_y, normalize='pred')\n",
    "\n",
    "    def _dataset_from_folder(self, folder):\n",
    "        return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            folder,\n",
    "            labels='inferred',\n",
    "            label_mode='categorical',\n",
    "            color_mode='grayscale',\n",
    "            batch_size=50,\n",
    "            image_size=(256, 256),\n",
    "            seed=2,\n",
    "        )\n",
    "\n",
    "    def _create_model(self):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Conv2D(32, (12, 12), activation='relu',\n",
    "                                input_shape=(256, 256, 1)),\n",
    "            keras.layers.MaxPooling2D((8, 8)),\n",
    "            keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            keras.layers.MaxPooling2D((2, 2)),\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(128, activation='relu'),\n",
    "            keras.layers.Dropout(0.1),\n",
    "            keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb88e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifier import UrbanSoundClassifier\n",
    "\n",
    "classifier = UrbanSoundClassifier(ds)\n",
    "classifier.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1_multimedia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
