{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "352a7dfd-273c-440e-882f-c16a26c3187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import pandas.plotting as pd_plot\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.model_selection as ModelSelection\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0b800-76b7-4223-af29-9dec5693f4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_expand_and_fill(df_a, df_b):\n",
    "    df_a = df_a[df_b.columns.intersection(df_a.columns)]\n",
    "    missing_columns = [col for col in df_b.columns if col not in df_a.columns]\n",
    "    for col in missing_columns:\n",
    "        df_a[col] = 0\n",
    "    df_a = df_a[df_b.columns]\n",
    "    return df_a\n",
    "    \n",
    "# importing local modules is pain, so base code located here.\n",
    "class GenericTrainDataset:\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "\n",
    "    def _split_numeric(self, df):\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        non_numeric_df = df.select_dtypes(exclude=['number'])\n",
    "        return numeric_df, non_numeric_df\n",
    "\n",
    "    def _impute_nums(self, df):\n",
    "        num, non_num = self._split_numeric(df)\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        imputer.fit(num)\n",
    "        X = imputer.transform(num)\n",
    "        num_imputed = pd.DataFrame(X, columns=num.columns, index=num.index)\n",
    "        return pd.concat([non_num, num_imputed], axis=1)\n",
    "\n",
    "    def _prepare_non_nums(self, df):\n",
    "        num, non_num = self._split_numeric(df)\n",
    "        return pd.concat([num, pd.get_dummies(non_num)], axis=1)\n",
    "\n",
    "    def _scale_features(self, df):\n",
    "        return pd.DataFrame(StandardScaler().fit_transform(df.copy()), columns=df.columns, index=df.index)\n",
    "    \n",
    "    def prepare(self, target, test):\n",
    "        prepared = self._prepare_non_nums(self._impute_nums(self._df))\n",
    "        if test:\n",
    "            features = self._scale_features(prepared)\n",
    "            return features\n",
    "        features = self._scale_features(prepared.drop(columns=[target]))\n",
    "        labels = prepared[target]\n",
    "        return features, labels\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self):\n",
    "        raw_data = pd.read_csv(\"./data/train.csv\")\n",
    "        self._final_test = self.__prepare(pd.read_csv(\"./data/test.csv\"))\n",
    "        self._train = self.__prepare(raw_data)\n",
    "    \n",
    "    def __prepare(self, rawDf):\n",
    "        df = rawDf.copy()\n",
    "        df = df.drop(columns=[\"Id\"])\n",
    "        df = self.__gen_data(df)\n",
    "        return df\n",
    "\n",
    "    def __gen_data(self, df):\n",
    "        df[\"Age\"] = df[\"YearBuilt\"].max()-df[\"YearBuilt\"]\n",
    "        return df.drop(columns=[\"YearBuilt\"])\n",
    "\n",
    "    \n",
    "    def _info(self):\n",
    "        print(self._train.info())\n",
    "        print(self._train.describe())\n",
    "\n",
    "    def _show(self):\n",
    "        self._train.hist(bins=50, figsize=(20,15))\n",
    "        plt.show()\n",
    "        \n",
    "    def _correlation(self):\n",
    "        corr_matrix = self._train.corr(numeric_only=True)\n",
    "        print(\"================correlation(abs)================\\n\\n\")\n",
    "        print(corr_matrix[\"SalePrice\"].abs().sort_values(ascending=False))\n",
    "        print(\"================correlation(abs)================\\n\\n\")\n",
    "\n",
    "    def _get_most_correlated_attrs(self):\n",
    "        corr_matrix = self._train.corr(numeric_only=True)\n",
    "        sorted = corr_matrix[\"SalePrice\"].abs().sort_values(ascending=False).head(10)\n",
    "        return [(index) for index in sorted.index]\n",
    "    \n",
    "    def _scatter(self):\n",
    "        print(\"================top 10 correlated(abs) features scatter pl================\\n\\n\")\n",
    "        attrs = self._get_most_correlated_attrs()\n",
    "        pd_plot.scatter_matrix(self._train[attrs], figsize=(20,10))\n",
    "        \n",
    "    \n",
    "    def describe(self):\n",
    "        self._info()\n",
    "        self._show()\n",
    "        self._correlation()\n",
    "        self._scatter()\n",
    "\n",
    "\n",
    "    def make_train_frame(self):\n",
    "        df = self._train\n",
    "        # df = self._train[(self._train[\"SalePrice\"] >= 50000) & (self._train[\"SalePrice\"] <= 400000)]\n",
    "        dataset = GenericTrainDataset(df)\n",
    "        features, labels = dataset.prepare(\"SalePrice\", False)\n",
    "        return features, labels\n",
    "\n",
    "    def make_test_frame(self):\n",
    "        df = self._final_test\n",
    "        # df = self._test[(self._test[\"SalePrice\"] >= 50000) & (self._test[\"SalePrice\"] <= 400000)]\n",
    "        dataset = GenericTrainDataset(df)\n",
    "        return dataset.prepare(\"SalePrice\", True)\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # Data should not contain NaN's\n",
    "    def __init__(self, data):\n",
    "        self._data = data\n",
    "\n",
    "    def test_prediction(self, RegressorModel):\n",
    "        featured_df, labels = self._data.make_train_frame()\n",
    "        reg=RegressorModel(l1_ratio=0.2)\n",
    "        reg.fit(featured_df, labels)\n",
    "        featured_test_df = self._data.make_test_frame()\n",
    "\n",
    "        ds = align_expand_and_fill(featured_test_df, featured_df).sort_index()\n",
    "        prediction = reg.predict(ds)\n",
    "        df = pd.DataFrame({})\n",
    "        df['SalePrice']=prediction\n",
    "        df['Id'] = df.index + 1461\n",
    "        return df\n",
    "    \n",
    "    def simple_train_and_cv(self, RegressorModel):\n",
    "        featured_df, labels = self._data.make_train_frame()\n",
    "        reg=RegressorModel()\n",
    "        reg.fit(featured_df, labels)\n",
    "        prediction = reg.predict(featured_df)\n",
    "        lin_mse = mean_squared_error(labels, prediction)\n",
    "        lin_rmse = np.sqrt(lin_mse)\n",
    "        \n",
    "        print(\"================{}================\\n\\n\".format(RegressorModel))\n",
    "        predictions = reg.predict(featured_df)\n",
    "        mse = mean_squared_error(labels, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(\"RMSE on validation set: {}\".format(rmse))\n",
    "        self._cross_validate(reg)\n",
    "        print(\"\\n\\n================{}================\\n\\n\".format(RegressorModel))\n",
    "\n",
    "    def _cross_validate(self, reg):\n",
    "        featured_df, labels = self._data.make_train_frame()\n",
    "        category_bins = pd.cut(labels, bins=10, labels=False)  \n",
    "        skf = StratifiedKFold(n_splits=20)\n",
    "        generator = skf.split(labels, category_bins)\n",
    "        scores = cross_val_score(reg, featured_df, labels, scoring=\"neg_mean_squared_error\", cv=generator)\n",
    "        rmse_scores = np.sqrt(np.log(-scores))\n",
    "        self._display_scores(rmse_scores)\n",
    "\n",
    "    def _display_scores(self, scores):\n",
    "        print(\"\\nCV errors(lower is better):\", scores)\n",
    "        print(\"CV errors Mean(lower is better):\", scores.mean())\n",
    "        print(\"CV errors Standard deviation(lower is better): {} \\n\".format(scores.std()))\n",
    "        \n",
    "data = Data()\n",
    "data.describe()\n",
    "model = Model(data)\n",
    "model.simple_train_and_cv(ElasticNet)\n",
    "model.simple_train_and_cv(DecisionTreeRegressor)\n",
    "model.simple_train_and_cv(RandomForestRegressor)\n",
    "print(\"start\")\n",
    "model.test_prediction(ElasticNet).to_csv('result.csv', index=False)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88da7a4-c8ee-4fb1-96f1-730d3e1b9bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c6060-b8eb-4a82-ade4-2c42a2f38159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
